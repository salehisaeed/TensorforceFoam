{"agent": "ppo", "states": {"type": "float", "shape": [99]}, "actions": {"type": "float", "min_value": -1.0, "max_value": 1.0}, "max_episode_timesteps": 400, "batch_size": 5, "network": [{"type": "dense", "size": 64}, {"type": "dense", "size": 64}], "use_beta_distribution": false, "memory": "minimum", "update_frequency": 5, "learning_rate": 0.0005, "multi_step": 12, "subsampling_fraction": 0.333, "likelihood_ratio_clipping": 0.2, "discount": 0.99, "return_processing": null, "advantage_processing": null, "predict_terminal_values": false, "baseline": [{"type": "dense", "size": 64}, {"type": "dense", "size": 64}], "baseline_optimizer": {"optimizer": "adam", "learning_rate": 0.001, "multi_step": 10}, "state_preprocessing": null, "exploration": 0.0, "variable_noise": 0.0, "l2_regularization": 0.0, "entropy_regularization": 0.0, "parallel_interactions": 1, "config": null, "saver": {"directory": "model", "frequency": 1, "max_checkpoints": 100}, "summarizer": {"directory": "summaries", "summaries": "all", "max_summaries": 10}, "tracking": null, "recorder": null, "internals": {}, "initial_internals": {"policy": {}, "baseline": {}}}